{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Wrangling Lab**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimated time needed: **45** minutes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you will perform data wrangling tasks to prepare raw data for analysis. Data wrangling involves cleaning, transforming, and organizing data into a structured format suitable for analysis. This lab focuses on tasks like identifying inconsistencies, encoding categorical variables, and feature transformation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After completing this lab, you will be able to:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Identify and remove inconsistent data entries.\n",
    "\n",
    "- Encode categorical variables for analysis.\n",
    "\n",
    "- Handle missing values using multiple imputation strategies.\n",
    "\n",
    "- Apply feature scaling and transformation techniques.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Intsall the required libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "Collecting numpy>=1.26.0 (from pandas)\n",
      "  Downloading numpy-2.2.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.7/12.7 MB\u001b[0m \u001b[31m145.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Downloading numpy-2.2.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.1/16.1 MB\u001b[0m \u001b[31m179.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: tzdata, numpy, pandas\n",
      "Successfully installed numpy-2.2.5 pandas-2.2.3 tzdata-2025.2\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.57.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (102 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.8-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (2.2.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (24.2)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Downloading pillow-11.2.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (8.9 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Downloading pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Downloading matplotlib-3.10.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m120.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (323 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.57.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m141.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Downloading kiwisolver-1.4.8-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m86.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pillow-11.2.1-cp312-cp312-manylinux_2_28_x86_64.whl (4.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m149.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Installing collected packages: pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.3.2 cycler-0.12.1 fonttools-4.57.0 kiwisolver-1.4.8 matplotlib-3.10.1 pillow-11.2.1 pyparsing-3.2.3\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /opt/conda/lib/python3.12/site-packages (from scikit-learn) (2.2.5)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.15.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.6.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m146.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading scipy-1.15.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.3/37.3 MB\u001b[0m \u001b[31m161.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.6.1 scipy-1.15.2 threadpoolctl-3.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Import the necessary module.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>1.1 Import necessary libraries and load the dataset.</h5>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure the dataset is loaded correctly by displaying the first few rows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ResponseId                      MainBranch                 Age  \\\n",
      "0           1  I am a developer by profession  Under 18 years old   \n",
      "1           2  I am a developer by profession     35-44 years old   \n",
      "2           3  I am a developer by profession     45-54 years old   \n",
      "3           4           I am learning to code     18-24 years old   \n",
      "4           5  I am a developer by profession     18-24 years old   \n",
      "\n",
      "            Employment RemoteWork   Check  \\\n",
      "0  Employed, full-time     Remote  Apples   \n",
      "1  Employed, full-time     Remote  Apples   \n",
      "2  Employed, full-time     Remote  Apples   \n",
      "3   Student, full-time        NaN  Apples   \n",
      "4   Student, full-time        NaN  Apples   \n",
      "\n",
      "                                    CodingActivities  \\\n",
      "0                                              Hobby   \n",
      "1  Hobby;Contribute to open-source projects;Other...   \n",
      "2  Hobby;Contribute to open-source projects;Other...   \n",
      "3                                                NaN   \n",
      "4                                                NaN   \n",
      "\n",
      "                                             EdLevel  \\\n",
      "0                          Primary/elementary school   \n",
      "1       Bachelor’s degree (B.A., B.S., B.Eng., etc.)   \n",
      "2    Master’s degree (M.A., M.S., M.Eng., MBA, etc.)   \n",
      "3  Some college/university study without earning ...   \n",
      "4  Secondary school (e.g. American high school, G...   \n",
      "\n",
      "                                           LearnCode  \\\n",
      "0                             Books / Physical media   \n",
      "1  Books / Physical media;Colleague;On the job tr...   \n",
      "2  Books / Physical media;Colleague;On the job tr...   \n",
      "3  Other online resources (e.g., videos, blogs, f...   \n",
      "4  Other online resources (e.g., videos, blogs, f...   \n",
      "\n",
      "                                     LearnCodeOnline  ... JobSatPoints_6  \\\n",
      "0                                                NaN  ...            NaN   \n",
      "1  Technical documentation;Blogs;Books;Written Tu...  ...            0.0   \n",
      "2  Technical documentation;Blogs;Books;Written Tu...  ...            NaN   \n",
      "3  Stack Overflow;How-to videos;Interactive tutorial  ...            NaN   \n",
      "4  Technical documentation;Blogs;Written Tutorial...  ...            NaN   \n",
      "\n",
      "  JobSatPoints_7 JobSatPoints_8 JobSatPoints_9 JobSatPoints_10  \\\n",
      "0            NaN            NaN            NaN             NaN   \n",
      "1            0.0            0.0            0.0             0.0   \n",
      "2            NaN            NaN            NaN             NaN   \n",
      "3            NaN            NaN            NaN             NaN   \n",
      "4            NaN            NaN            NaN             NaN   \n",
      "\n",
      "  JobSatPoints_11           SurveyLength SurveyEase ConvertedCompYearly JobSat  \n",
      "0             NaN                    NaN        NaN                 NaN    NaN  \n",
      "1             0.0                    NaN        NaN                 NaN    NaN  \n",
      "2             NaN  Appropriate in length       Easy                 NaN    NaN  \n",
      "3             NaN               Too long       Easy                 NaN    NaN  \n",
      "4             NaN              Too short       Easy                 NaN    NaN  \n",
      "\n",
      "[5 rows x 114 columns]\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "# Load the Stack Overflow survey data\n",
    "dataset_url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/n01PQ9pSmiRX6520flujwQ/survey-data.csv\"\n",
    "df = pd.read_csv(dataset_url)\n",
    "\n",
    "# Display the first few rows\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Explore the Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>2.1 Summarize the dataset by displaying the column data types, counts, and missing values.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows (excluding 'ResponseId'): 487\n"
     ]
    }
   ],
   "source": [
    "duplicates = df.drop(columns=['ResponseId']).duplicated()\n",
    "num_duplicates = duplicates.sum()\n",
    "print(\"Number of duplicate rows (excluding 'ResponseId'):\", num_duplicates)\n",
    "df_cleaned=df[~duplicates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 64950 entries, 0 to 65436\n",
      "Columns: 114 entries, ResponseId to JobSat\n",
      "dtypes: float64(13), int64(1), object(100)\n",
      "memory usage: 57.0+ MB\n",
      "None\n",
      "\n",
      "Missing values per column:\n",
      " ResponseId                 0\n",
      "MainBranch                 0\n",
      "Age                        0\n",
      "Employment                 0\n",
      "RemoteWork             10546\n",
      "                       ...  \n",
      "JobSatPoints_11        35505\n",
      "SurveyLength            8768\n",
      "SurveyEase              8712\n",
      "ConvertedCompYearly    41515\n",
      "JobSat                 35824\n",
      "Length: 114, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Write your code here\n",
    "print(df_cleaned.info())\n",
    "\n",
    "# Count of missing values per column\n",
    "missing_counts = df_cleaned.isnull().sum()\n",
    "print(\"\\nMissing values per column:\\n\", missing_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>2.2 Generate basic statistics for numerical columns.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         ResponseId      CompTotal       WorkExp  JobSatPoints_1  \\\n",
      "count  64950.000000   3.374000e+04  29658.000000    29324.000000   \n",
      "mean   32511.068822  2.963841e+145     11.466957       18.581094   \n",
      "std    18802.882779  5.444117e+147      9.168709       25.966221   \n",
      "min        1.000000   0.000000e+00      0.000000        0.000000   \n",
      "25%    16238.250000   6.000000e+04      4.000000        0.000000   \n",
      "50%    32475.500000   1.100000e+05      9.000000       10.000000   \n",
      "75%    48733.750000   2.500000e+05     16.000000       22.000000   \n",
      "max    65437.000000  1.000000e+150     50.000000      100.000000   \n",
      "\n",
      "       JobSatPoints_4  JobSatPoints_5  JobSatPoints_6  JobSatPoints_7  \\\n",
      "count    29393.000000    29411.000000    29450.000000     29448.00000   \n",
      "mean         7.522140       10.060857       24.343232        22.96522   \n",
      "std         18.422661       21.833836       27.089360        27.01774   \n",
      "min          0.000000        0.000000        0.000000         0.00000   \n",
      "25%          0.000000        0.000000        0.000000         0.00000   \n",
      "50%          0.000000        0.000000       20.000000        15.00000   \n",
      "75%          5.000000       10.000000       30.000000        30.00000   \n",
      "max        100.000000      100.000000      100.000000       100.00000   \n",
      "\n",
      "       JobSatPoints_8  JobSatPoints_9  JobSatPoints_10  JobSatPoints_11  \\\n",
      "count    29456.000000    29456.000000     29450.000000     29445.000000   \n",
      "mean        20.278165       16.169432        10.955713         9.953948   \n",
      "std         26.108110       24.845032        22.906263        21.775652   \n",
      "min          0.000000        0.000000         0.000000         0.000000   \n",
      "25%          0.000000        0.000000         0.000000         0.000000   \n",
      "50%         10.000000        5.000000         0.000000         0.000000   \n",
      "75%         25.000000       20.000000        10.000000        10.000000   \n",
      "max        100.000000      100.000000       100.000000       100.000000   \n",
      "\n",
      "       ConvertedCompYearly        JobSat  \n",
      "count         2.343500e+04  29126.000000  \n",
      "mean          8.615529e+04      6.935041  \n",
      "std           1.867570e+05      2.088259  \n",
      "min           1.000000e+00      0.000000  \n",
      "25%           3.271200e+04      6.000000  \n",
      "50%           6.500000e+04      7.000000  \n",
      "75%           1.079715e+05      8.000000  \n",
      "max           1.625660e+07     10.000000  \n"
     ]
    }
   ],
   "source": [
    "# Write your code here\n",
    "print(df_cleaned.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Identifying and Removing Inconsistencies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>3.1 Identify inconsistent or irrelevant entries in specific columns (e.g., Country).</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EdLevel\n",
      "Bachelor’s degree (B.A., B.S., B.Eng., etc.)                                          24942\n",
      "Master’s degree (M.A., M.S., M.Eng., MBA, etc.)                                       15557\n",
      "Some college/university study without earning a degree                                 7651\n",
      "Secondary school (e.g. American high school, German Realschule or Gymnasium, etc.)     5793\n",
      "NaN                                                                                    4166\n",
      "Professional degree (JD, MD, Ph.D, Ed.D, etc.)                                         2970\n",
      "Associate degree (A.A., A.S., etc.)                                                    1793\n",
      "Primary/elementary school                                                              1146\n",
      "Something else                                                                          932\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Write your code here\n",
    "print(df_cleaned['EdLevel'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Country\n",
       "United States of America                                11095\n",
       "NaN                                                      6020\n",
       "Germany                                                  4947\n",
       "India                                                    4231\n",
       "United Kingdom of Great Britain and Northern Ireland     3224\n",
       "Ukraine                                                  2672\n",
       "France                                                   2110\n",
       "Canada                                                   2104\n",
       "Poland                                                   1534\n",
       "Netherlands                                              1449\n",
       "Brazil                                                   1375\n",
       "Italy                                                    1341\n",
       "Australia                                                1260\n",
       "Spain                                                    1123\n",
       "Sweden                                                   1016\n",
       "Russian Federation                                        925\n",
       "Switzerland                                               876\n",
       "Austria                                                   791\n",
       "Czech Republic                                            714\n",
       "Israel                                                    604\n",
       "Turkey                                                    546\n",
       "Belgium                                                   526\n",
       "Denmark                                                   504\n",
       "Portugal                                                  470\n",
       "Norway                                                    450\n",
       "Romania                                                   439\n",
       "Pakistan                                                  415\n",
       "Iran, Islamic Republic of...                              411\n",
       "China                                                     406\n",
       "Mexico                                                    402\n",
       "Hungary                                                   396\n",
       "New Zealand                                               396\n",
       "Greece                                                    389\n",
       "Finland                                                   386\n",
       "South Africa                                              358\n",
       "Indonesia                                                 354\n",
       "Argentina                                                 345\n",
       "Bangladesh                                                327\n",
       "Bulgaria                                                  319\n",
       "Nigeria                                                   305\n",
       "Viet Nam                                                  296\n",
       "Japan                                                     288\n",
       "Ireland                                                   270\n",
       "Taiwan                                                    268\n",
       "Egypt                                                     262\n",
       "Slovakia                                                  248\n",
       "Serbia                                                    245\n",
       "Colombia                                                  217\n",
       "Philippines                                               196\n",
       "Croatia                                                   187\n",
       "Lithuania                                                 183\n",
       "Kenya                                                     180\n",
       "Singapore                                                 177\n",
       "Sri Lanka                                                 163\n",
       "Malaysia                                                  161\n",
       "Thailand                                                  147\n",
       "South Korea                                               146\n",
       "Hong Kong (S.A.R.)                                        146\n",
       "Slovenia                                                  142\n",
       "Nepal                                                     139\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country= df_cleaned['Country'].value_counts(dropna=False)\n",
    "#country.tail(50)\n",
    "country.head(60)\n",
    "#print(df_cleaned['Country'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Country\n",
       "Malawi                                   12\n",
       "Benin                                    11\n",
       "Jamaica                                  11\n",
       "Turkmenistan                             11\n",
       "Bahrain                                  11\n",
       "Mongolia                                 10\n",
       "Senegal                                   9\n",
       "Togo                                      9\n",
       "Somalia                                   9\n",
       "Trinidad and Tobago                       8\n",
       "Oman                                      8\n",
       "Congo, Republic of the...                 8\n",
       "Kuwait                                    8\n",
       "Sudan                                     7\n",
       "Mozambique                                7\n",
       "Tajikistan                                7\n",
       "Barbados                                  6\n",
       "Mauritania                                5\n",
       "Botswana                                  5\n",
       "Cape Verde                                5\n",
       "Suriname                                  5\n",
       "Antigua and Barbuda                       5\n",
       "Namibia                                   5\n",
       "Lao People's Democratic Republic          4\n",
       "Liechtenstein                             4\n",
       "Fiji                                      4\n",
       "Bahamas                                   4\n",
       "Gabon                                     4\n",
       "Liberia                                   4\n",
       "Swaziland                                 4\n",
       "Libyan Arab Jamahiriya                    4\n",
       "Burkina Faso                              4\n",
       "San Marino                                3\n",
       "North Korea                               3\n",
       "Democratic Republic of the Congo          3\n",
       "Burundi                                   3\n",
       "Sierra Leone                              3\n",
       "Monaco                                    3\n",
       "Bhutan                                    3\n",
       "Guyana                                    3\n",
       "Brunei Darussalam                         3\n",
       "Mali                                      2\n",
       "Democratic People's Republic of Korea     2\n",
       "Guinea-Bissau                             2\n",
       "Belize                                    2\n",
       "Dominica                                  1\n",
       "Papua New Guinea                          1\n",
       "Central African Republic                  1\n",
       "Equatorial Guinea                         1\n",
       "Samoa                                     1\n",
       "Guinea                                    1\n",
       "Niger                                     1\n",
       "Saint Kitts and Nevis                     1\n",
       "Lesotho                                   1\n",
       "Haiti                                     1\n",
       "Micronesia, Federated States of...        1\n",
       "Nauru                                     1\n",
       "Chad                                      1\n",
       "Djibouti                                  1\n",
       "Solomon Islands                           1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country.tail(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>3.2 Standardize entries in columns like Country or EdLevel by mapping inconsistent values to a consistent format.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your code here\n",
    "               \n",
    "edlevel_mapping = {\n",
    "    \"Bachelor’s degree (B.A., B.S., B.Eng., etc.)\": \"Bachelor’s degree\",\n",
    "    \"Master’s degree (M.A., M.S., M.Eng., MBA, etc.)\": \"Master’s degree\",\n",
    "    \"Professional degree (JD, MD, Ph.D, Ed.D, etc.)\": \"Professional degree\",\n",
    "    \"Associate degree (A.A., A.S., etc.)\": \"Associate degree\",\n",
    "    \"Some college/university study without earning a degree\": \"College/University without degree\",\n",
    "    \"Secondary school (e.g. American high school, German Realschule or Gymnasium, etc.)\": \"Secondary school\",\n",
    "    \"Primary/elementary school\": \"Primary school\",\n",
    "    \"Something else\": \"Other\"\n",
    "}\n",
    "df_cleaned.loc[:,'EdLevel'] = df_cleaned['EdLevel'].str.strip().map(edlevel_mapping)\n",
    "df_cleaned.loc[:,'EdLevel']=df_cleaned['EdLevel'].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EdLevel\n",
      "Bachelor’s degree                    24942\n",
      "Master’s degree                      15557\n",
      "College/University without degree     7651\n",
      "Secondary school                      5793\n",
      "Unknown                               4166\n",
      "Professional degree                   2970\n",
      "Associate degree                      1793\n",
      "Primary school                        1146\n",
      "Other                                  932\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_cleaned['EdLevel'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country\n",
      "United States      11095\n",
      "NaN                 6020\n",
      "Germany             4947\n",
      "India               4231\n",
      "United Kingdom      3224\n",
      "                   ...  \n",
      "Micronesia             1\n",
      "Nauru                  1\n",
      "Chad                   1\n",
      "Djibouti               1\n",
      "Solomon Islands        1\n",
      "Name: count, Length: 185, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "country_mapping = {\n",
    "    \"Congo, Republic of the...\": \"Congo\",\n",
    "    \"Democratic Republic of the Congo\": \"Congo\",\n",
    "    \"Lao People's Democratic Republic\": \"Lao\",\n",
    "    \"Libyan Arab Jamahiriya\": \"Libyan\",\n",
    "    \"Democratic People's Republic of Korea\": \"Korea\",\n",
    "    \"Micronesia, Federated States of...\": \"Micronesia\",\n",
    "    \"Democratic People's Republic of Korea\": \"Korea\",\n",
    "    \"United States of America\": \"United States\",\n",
    "    \"United Kingdom of Great Britain and Northern Ireland\": \"United Kingdom\",\n",
    "    \"Russian Federation\":\"Russian\",\n",
    "    \"Czech Republic\":\"Czech\",\n",
    "    \"Iran, Islamic Republic of...\":\"Iran\",\n",
    "    \"Hong Kong (S.A.R.)\":\"Hong Kong\",\n",
    "    \"Viet Nam\":\"VietNam\"\n",
    "}\n",
    "#df_cleaned.loc[:,'Country'] = df_cleaned['Country'].str.strip().map(country_mapping)\n",
    "df_cleaned.loc[:,'Country'] = df_cleaned['Country'].str.strip()\n",
    "\n",
    "#Replace only matching entries, keep others\n",
    "df_cleaned.loc[:, 'Country'] = df_cleaned['Country'].replace(country_mapping)\n",
    "\n",
    "print(df_cleaned['Country'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Country\n",
       "Malawi                                   12\n",
       "Benin                                    11\n",
       "Jamaica                                  11\n",
       "Turkmenistan                             11\n",
       "Bahrain                                  11\n",
       "Mongolia                                 10\n",
       "Senegal                                   9\n",
       "Togo                                      9\n",
       "Somalia                                   9\n",
       "Trinidad and Tobago                       8\n",
       "Oman                                      8\n",
       "Congo, Republic of the...                 8\n",
       "Kuwait                                    8\n",
       "Sudan                                     7\n",
       "Mozambique                                7\n",
       "Tajikistan                                7\n",
       "Barbados                                  6\n",
       "Mauritania                                5\n",
       "Botswana                                  5\n",
       "Cape Verde                                5\n",
       "Suriname                                  5\n",
       "Antigua and Barbuda                       5\n",
       "Namibia                                   5\n",
       "Lao People's Democratic Republic          4\n",
       "Liechtenstein                             4\n",
       "Fiji                                      4\n",
       "Bahamas                                   4\n",
       "Gabon                                     4\n",
       "Liberia                                   4\n",
       "Swaziland                                 4\n",
       "Libyan Arab Jamahiriya                    4\n",
       "Burkina Faso                              4\n",
       "San Marino                                3\n",
       "North Korea                               3\n",
       "Democratic Republic of the Congo          3\n",
       "Burundi                                   3\n",
       "Sierra Leone                              3\n",
       "Monaco                                    3\n",
       "Bhutan                                    3\n",
       "Guyana                                    3\n",
       "Brunei Darussalam                         3\n",
       "Mali                                      2\n",
       "Democratic People's Republic of Korea     2\n",
       "Guinea-Bissau                             2\n",
       "Belize                                    2\n",
       "Dominica                                  1\n",
       "Papua New Guinea                          1\n",
       "Central African Republic                  1\n",
       "Equatorial Guinea                         1\n",
       "Samoa                                     1\n",
       "Guinea                                    1\n",
       "Niger                                     1\n",
       "Saint Kitts and Nevis                     1\n",
       "Lesotho                                   1\n",
       "Haiti                                     1\n",
       "Micronesia, Federated States of...        1\n",
       "Nauru                                     1\n",
       "Chad                                      1\n",
       "Djibouti                                  1\n",
       "Solomon Islands                           1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country= df_cleaned['Country'].value_counts(dropna=False)\n",
    "country.tail(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Encoding Categorical Variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>4.1 Encode the Employment column using one-hot encoding.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your code here\n",
    "\n",
    "df_cleaned.loc[:, 'Employment'] = df_cleaned['Employment'].fillna(\"\")\n",
    "\n",
    "#Split the values in 'Employment' column into lists\n",
    "if 'Employment_split' not in df_cleaned.columns:\n",
    "    df_cleaned.loc[:, 'Employment'] = df_cleaned['Employment'].fillna(\"\")\n",
    "    df_cleaned.loc[:, 'Employment_split'] = df_cleaned['Employment'].apply(lambda x: [val.strip() for val in x.split(';')])\n",
    "\n",
    "    from sklearn.preprocessing import MultiLabelBinarizer\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    employment_dummies = pd.DataFrame(mlb.fit_transform(df_cleaned['Employment_split']),\n",
    "                                       columns=mlb.classes_,\n",
    "                                       index=df_cleaned.index)\n",
    "\n",
    "    # Only add new columns if they don't already exist\n",
    "    df_cleaned = pd.concat([df_cleaned, employment_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JobSatPoints_6</th>\n",
       "      <th>JobSatPoints_7</th>\n",
       "      <th>JobSatPoints_8</th>\n",
       "      <th>JobSatPoints_9</th>\n",
       "      <th>JobSatPoints_10</th>\n",
       "      <th>JobSatPoints_11</th>\n",
       "      <th>SurveyLength</th>\n",
       "      <th>SurveyEase</th>\n",
       "      <th>ConvertedCompYearly</th>\n",
       "      <th>JobSat</th>\n",
       "      <th>Employment_split</th>\n",
       "      <th>Employed, full-time</th>\n",
       "      <th>Employed, part-time</th>\n",
       "      <th>I prefer not to say</th>\n",
       "      <th>Independent contractor, freelancer, or self-employed</th>\n",
       "      <th>Not employed, and not looking for work</th>\n",
       "      <th>Not employed, but looking for work</th>\n",
       "      <th>Retired</th>\n",
       "      <th>Student, full-time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Employed, full-time]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Employed, full-time]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Appropriate in length</td>\n",
       "      <td>Easy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Employed, full-time]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Too long</td>\n",
       "      <td>Easy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Student, full-time]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Too short</td>\n",
       "      <td>Easy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Student, full-time]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   JobSatPoints_6  JobSatPoints_7  JobSatPoints_8  JobSatPoints_9  \\\n",
       "0             NaN             NaN             NaN             NaN   \n",
       "1             0.0             0.0             0.0             0.0   \n",
       "2             NaN             NaN             NaN             NaN   \n",
       "3             NaN             NaN             NaN             NaN   \n",
       "4             NaN             NaN             NaN             NaN   \n",
       "\n",
       "   JobSatPoints_10  JobSatPoints_11           SurveyLength SurveyEase  \\\n",
       "0              NaN              NaN                    NaN        NaN   \n",
       "1              0.0              0.0                    NaN        NaN   \n",
       "2              NaN              NaN  Appropriate in length       Easy   \n",
       "3              NaN              NaN               Too long       Easy   \n",
       "4              NaN              NaN              Too short       Easy   \n",
       "\n",
       "   ConvertedCompYearly  JobSat       Employment_split  Employed, full-time  \\\n",
       "0                  NaN     NaN  [Employed, full-time]                    1   \n",
       "1                  NaN     NaN  [Employed, full-time]                    1   \n",
       "2                  NaN     NaN  [Employed, full-time]                    1   \n",
       "3                  NaN     NaN   [Student, full-time]                    0   \n",
       "4                  NaN     NaN   [Student, full-time]                    0   \n",
       "\n",
       "   Employed, part-time  I prefer not to say  \\\n",
       "0                    0                    0   \n",
       "1                    0                    0   \n",
       "2                    0                    0   \n",
       "3                    0                    0   \n",
       "4                    0                    0   \n",
       "\n",
       "   Independent contractor, freelancer, or self-employed  \\\n",
       "0                                                  0      \n",
       "1                                                  0      \n",
       "2                                                  0      \n",
       "3                                                  0      \n",
       "4                                                  0      \n",
       "\n",
       "   Not employed, and not looking for work  Not employed, but looking for work  \\\n",
       "0                                       0                                   0   \n",
       "1                                       0                                   0   \n",
       "2                                       0                                   0   \n",
       "3                                       0                                   0   \n",
       "4                                       0                                   0   \n",
       "\n",
       "   Retired  Student, full-time  \n",
       "0        0                   0  \n",
       "1        0                   0  \n",
       "2        0                   0  \n",
       "3        0                   1  \n",
       "4        0                   1  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.iloc[:,-20:-1 ].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Handling Missing Values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>5.1 Identify columns with the highest number of missing values.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with the most missing values:\n",
      "AINextMuch less integrated    63802\n",
      "AINextLess integrated         62595\n",
      "AINextNo change               52452\n",
      "AINextMuch more integrated    51512\n",
      "EmbeddedAdmired               48217\n",
      "                              ...  \n",
      "LanguageHaveWorkedWith         5205\n",
      "YearsCode                      5081\n",
      "NEWSOSites                     4669\n",
      "LearnCode                      4462\n",
      "AISelect                       4051\n",
      "Length: 108, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "missing_counts = df_cleaned.isnull().sum().sort_values(ascending=False)\n",
    "print(\"Columns with the most missing values:\")\n",
    "print(missing_counts[missing_counts > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>5.2 Impute missing values in numerical columns (e.g., `ConvertedCompYearly`) with the mean or median.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your code here\n",
    "mean_value = df_cleaned['ConvertedCompYearly'].mean()\n",
    "df_cleaned.fillna({'ConvertedCompYearly':mean_value}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>5.3 Impute missing values in categorical columns (e.g., `RemoteWork`) with the most frequent value.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your code here\n",
    "mostFrequent_RemoteWork=df_cleaned['RemoteWork'].mode()[0]\n",
    "df_cleaned.fillna({'RemoteWork':mostFrequent_RemoteWork}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Feature Scaling and Transformation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>6.1 Apply Min-Max Scaling to normalize the `ConvertedCompYearly` column.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your code here\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "df_cleaned['ConvertedCompYearly_MinMax'] = scaler.fit_transform(df_cleaned[['ConvertedCompYearly']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>6.2 Log-transform the ConvertedCompYearly column to reduce skewness.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your code here\n",
    "import numpy as np\n",
    "\n",
    "# Avoid errors from log(0) by filtering positive values only\n",
    "df_cleaned = df_cleaned[df_cleaned['ConvertedCompYearly'] > 0]\n",
    "df_cleaned['ConvertedCompYearly_Log'] = np.log(df_cleaned['ConvertedCompYearly'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Feature Engineering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>7.1 Create a new column `ExperienceLevel` based on the `YearsCodePro` column:</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        NaN\n",
       "1         17\n",
       "2         27\n",
       "3        NaN\n",
       "4        NaN\n",
       "        ... \n",
       "65432      3\n",
       "65433    NaN\n",
       "65434      5\n",
       "65435      2\n",
       "65436    NaN\n",
       "Name: YearsCodePro, Length: 64950, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned['YearsCodePro']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExperienceLevel\n",
      "Advanced        25703\n",
      "Unknown         16246\n",
      "Intermediate    16194\n",
      "Beginner         6807\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "# First, convert 'YearsCodePro' to numeric\n",
    "df_cleaned['YearsCodePro'] = pd.to_numeric(df_cleaned['YearsCodePro'], errors='coerce')\n",
    "\n",
    "# Define experience levels\n",
    "def experience_level(years):\n",
    "    if pd.isna(years):\n",
    "        return 'Unknown'\n",
    "    elif years < 3:\n",
    "        return 'Beginner'\n",
    "    elif years < 8:\n",
    "        return 'Intermediate'\n",
    "    else:\n",
    "        return 'Advanced'\n",
    "\n",
    "# Apply the function\n",
    "df_cleaned['ExperienceLevel'] = df_cleaned['YearsCodePro'].apply(experience_level)\n",
    "\n",
    "# Check the result\n",
    "print(df_cleaned['ExperienceLevel'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you:\n",
    "\n",
    "- Explored the dataset to identify inconsistencies and missing values.\n",
    "\n",
    "- Encoded categorical variables for analysis.\n",
    "\n",
    "- Handled missing values using imputation techniques.\n",
    "\n",
    "- Normalized and transformed numerical data to prepare it for analysis.\n",
    "\n",
    "- Engineered a new feature to enhance data interpretation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright © IBM Corporation. All rights reserved.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "prev_pub_hash": "1e8e234f19fd098e27b0518a87f18de690e1c51f1d3263d5690927d19971251e"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
